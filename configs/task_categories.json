{
    "copa_es": "Commonsense reasoning",
    "xnli_es": "Entailment",
    "xstorycloze_es": "Commonsense reasoning",
    "cocoteros_es": "Commonsense reasoning",
    "escola": "Language knowledge",
    "mgsm_direct_es": "Mathematical reasoning",
    "spabelebele": "Reading comprehension",
    "veritasqa_es_gen": "Truthfulness",
    "veritasqa_es_mc1": "Truthfulness",
    "veritasqa_es_mc2": "Truthfulness",
    "paws_es": "Paraphrase detection",
    "openbookqa_es": "Language-specific & world knowledge",
    "xquad_es": "Reading comprehension",
    "flores_en-es": "Machine translation",
    "include_spanish": "Language-specific & world knowledge",
    "global_mmlu_spanish": "Language-specific & world knowledge",
    "catbelebele": "Reading comprehension",
    "catcola": "Language knowledge",
    "cocoteros_va": "Commonsense reasoning",
    "flores_en-ca": "Machine translation",
    "mgsm_direct_ca": "Mathematical reasoning",
    "paws_ca": "Paraphrase detection",
    "veritasqa_ca_gen": "Truthfulness",
    "veritasqa_ca_mc1": "Truthfulness",
    "veritasqa_ca_mc2": "Truthfulness",
    "wnli_ca": "Entailment",
    "copa_ca": "Commonsense reasoning",
    "coqcat": "Reading comprehension",
    "parafraseja": "Paraphrase detection",
    "siqa_ca": "Commonsense reasoning",
    "teca": "Entailment",
    "piqa_ca": "Commonsense reasoning",
    "xstorycloze_ca": "Commonsense reasoning",
    "openbookqa_ca": "Language-specific & world knowledge",
    "xquad_ca": "Reading comprehension",
    "catalanqa": "Language-specific & world knowledge",
    "arc_ca_easy": "Language-specific & world knowledge",
    "arc_ca_challenge": "Language-specific & world knowledge",
    "xnli_ca": "Entailment",
    "arc_eu_easy": "Language-specific & world knowledge",
    "arc_eu_challenge": "Language-specific & world knowledge",
    "eus_proficiency": "Language-specific & world knowledge",
    "xcopa_eu": "Commonsense reasoning",
    "xstorycloze_eu": "Commonsense reasoning",
    "piqa_eu": "Commonsense reasoning",
    "eus_reading": "Reading comprehension",
    "eus_exams_eu": "Language-specific & world knowledge",
    "eus_trivia": "Language-specific & world knowledge",
    "eusbelebele": "Reading comprehension",
    "flores_en-eu": "Machine translation",
    "mgsm_direct_eu": "Mathematical reasoning",
    "paws_eu": "Paraphrase detection",
    "include_basque": "Language-specific & world knowledge",
    "xnli_eu_native": "Entailment",
    "wnli_eu": "Entailment",
    "openbookqa_gl": "Language-specific & world knowledge",
    "parafrases_gl": "Paraphrase detection",
    "mgsm_direct_gl": "Mathematical reasoning",
    "veritasqa_gl_gen": "Truthfulness",
    "veritasqa_gl_mc1": "Truthfulness",
    "veritasqa_gl_mc2": "Truthfulness",
    "galcola": "Language knowledge",
    "flores_en-gl": "Machine translation",
    "glgbelebele": "Reading comprehension",
    "paws_gl": "Paraphrase detection",
    "french_bench_reading": "Reading comprehension",
    "french_bench_vocabulary": "Language-specific & world knowledge",
    "french_bench_grammar": "Language-specific & world knowledge",
    "fquad": "Reading comprehension",
    "topic_based_nli": "Entailment",
    "frabelebele": "Reading comprehension",
    "french_xnli": "Entailment",
    "global_mmlu_french": "Language-specific & world knowledge",
    "include_french": "Language-specific & world knowledge",
    "norec_document": "Sentiment analysis",
    "noridiom_nob": "Language knowledge",
    "noridiom_nno": "Language knowledge",
    "nortruthfulqa_mc_nob": "Truthfulness",
    "norquad": "Reading comprehension",
    "noropenbookqa_nno": "Language-specific & world knowledge",
    "nortruthfulqa_mc_nno": "Truthfulness",
    "norcommonsenseqa_nno": "Commonsense reasoning",
    "norcommonsenseqa_nob": "Commonsense reasoning",
    "nrk_quiz_qa_nno": "Language-specific & world knowledge",
    "nrk_quiz_qa_nob": "Language-specific & world knowledge",
    "nortruthfulqa_gen_nob": "Truthfulness",
    "nortruthfulqa_gen_nno": "Truthfulness",
    "noropenbookqa_nob": "Language-specific & world knowledge",
    "norec_sentence": "Sentiment analysis",
    "tatoeba_eng_nob": "Machine translation",
    "tatoeba_eng_nno": "Machine translation",
    "norbelebele": "Reading comprehension",
    "ua_squad": "Reading comprehension",
    "wmt24pp_en-uk": "Machine translation",
    "include_ukrainian": "Language-specific & world knowledge",
    "zno": "Language-specific & world knowledge",
    "textdetox_ukr": "Toxicity detection",
    "ukrbelebele": "Reading comprehension",
    "global_mmlu_ukrainian": "Language-specific & world knowledge",
    "arc_challenge_fi_fbv2_mcf": "Language-specific & world knowledge",
    "arc_challenge_fi_fbv2_cf": "Language-specific & world knowledge",
    "belebele_fin_cf_fbv2": "Reading comprehension",
    "belebele_fin_mcf_fbv2": "Reading comprehension",
    "finbench_analogies_cf_fbv2": "Language-specific & world knowledge",
    "finbench_analogies_mcf_fbv2": "Language-specific & world knowledge",
    "finbench_emotions_cf_fbv2": "Sentiment analysis",
    "finbench_general_knowledge_cf_fbv2": "Language-specific & world knowledge",
    "finbench_general_knowledge_mcf_fbv2": "Language-specific & world knowledge",
    "finbench_hhh_alignment_cf_fbv2": "Toxicity detection",
    "finbench_hhh_alignment_mcf_fbv2": "Toxicity detection",
    "finbench_similarities_abstraction_cf_fbv2": "Commonsense reasoning",
    "finbench_similarities_abstraction_mcf_fbv2": "Commonsense reasoning",
    "goldenswag_ht_fi_cf_fbv2": "Commonsense reasoning",
    "goldenswag_ht_fi_mcf_fbv2": "Commonsense reasoning",
    "finbench_emotions_mcf_fbv2": "Sentiment analysis",
    "finbench_paraphrase_mcf_fbv2": "Paraphrase detection",
    "finbench_paraphrase_cf_fbv2": "Paraphrase detection",
    "finbench_empirical_judgments_mcf_fbv2": "Causal reasoning",
    "finbench_empirical_judgments_cf_fbv2": "Causal reasoning",
    "cs_sqad32": "Reading comprehension",
    "ces_subjectivity": "Sentiment analysis",
    "sentiment_csfd": "Sentiment analysis",
    "sentiment_fb": "Sentiment analysis",
    "sentiment_mall": "Sentiment analysis",
    "cermat_czech_mc": "Language knowledge",
    "cermat_czech_open": "Language knowledge",
    "cermat_czech_tf": "Language knowledge",
    "cermat_czmath_mc": "Mathematical reasoning",
    "cermat_czmath_open": "Mathematical reasoning",
    "klokan_qa": "Mathematical reasoning",
    "cesbelebele": "Reading comprehension",
    "ctkfacts_nli": "Entailment",
    "global_mmlu_czech": "Language-specific & world knowledge",
    "umimeto": "Language-specific & world knowledge"
}
